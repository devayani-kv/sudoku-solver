{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6098b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8645c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_many_images(images, titles, rows=1, columns=2):\n",
    "\t\"\"\"Plots each image in a given list as a grid structure. using Matplotlib.\"\"\"\n",
    "\tfor i, image in enumerate(images):\n",
    "\t\tplt.subplot(rows, columns, i+1)\n",
    "\t\tplt.imshow(image, 'gray')\n",
    "\t\tplt.title(titles[i])\n",
    "\t\tplt.xticks([]), plt.yticks([])  # Hide tick marks\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13980623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    \"\"\"Shows an image until any key is pressed\"\"\"\n",
    "#    print(type(img))\n",
    "#    print(img.shape)\n",
    "#    cv2.imshow('image', img)  # Display the image\n",
    "#    cv2.imwrite('images/gau_sudoku3.jpg', img)\n",
    "#    cv2.waitKey(0)  # Wait for any key to be pressed (with the image window active)\n",
    "#    cv2.destroyAllWindows()  # Close all windows\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb2cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digits(digits, colour=255):\n",
    "    \"\"\"Shows list of 81 extracted digits in a grid format\"\"\"\n",
    "    rows = []\n",
    "    with_border = [cv2.copyMakeBorder(img.copy(), 1, 1, 1, 1, cv2.BORDER_CONSTANT, None, colour) for img in digits]\n",
    "    for i in range(9):\n",
    "        row = np.concatenate(with_border[i * 9:((i + 1) * 9)], axis=1)\n",
    "        rows.append(row)\n",
    "    img = show_image(np.concatenate(rows))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce1c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_when_colour(colour, img):\n",
    "    \"\"\"Dynamically converts an image to colour if the input colour is a tuple and the image is grayscale.\"\"\"\n",
    "    if len(colour) == 3:\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        elif img.shape[2] == 1:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2af3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_points(in_img, points, radius=5, colour=(0, 0, 255)):\n",
    "    \"\"\"Draws circular points on an image.\"\"\"\n",
    "    img = in_img.copy()\n",
    "\n",
    "    # Dynamically change to a colour image if necessary\n",
    "    if len(colour) == 3:\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        elif img.shape[2] == 1:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for point in points:\n",
    "        img = cv2.circle(img, tuple(int(x) for x in point), radius, colour, -1)\n",
    "    show_image(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc34bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_rects(in_img, rects, colour=(0, 0, 255)):\n",
    "    img = convert_when_colour(colour, in_img.copy())\n",
    "    for rect in rects:\n",
    "        img = cv2.rectangle(img, tuple(int(x) for x in rect[0]), tuple(int(x) for x in rect[1]), colour)\n",
    "    show_image(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06458aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_contours(in_img, contours, colour=(0, 0, 255), thickness=2):\n",
    "    img = convert_when_colour(colour, in_img.copy())\n",
    "    img = cv2.drawContours(img, contours, -1, colour, thickness)\n",
    "    show_image(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06fa06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(img, skip_dilate=False):\n",
    "    \"\"\"Uses a blurring function, adaptive thresholding and dilation to expose the main features of an image.\"\"\"\n",
    "\n",
    "    # Gaussian blur with a kernal size (height, width) of 9.\n",
    "    # Note that kernal sizes must be positive and odd and the kernel must be square.\n",
    "    proc = cv2.GaussianBlur(img.copy(), (9, 9), 0)\n",
    "\n",
    "    # Adaptive threshold using 11 nearest neighbour pixels\n",
    "    proc = cv2.adaptiveThreshold(proc, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Invert colours, so gridlines have non-zero pixel values.\n",
    "    # Necessary to dilate the image, otherwise will look like erosion instead.\n",
    "    proc = cv2.bitwise_not(proc, proc)\n",
    "\n",
    "    if not skip_dilate:\n",
    "        # Dilate the image to increase the size of the grid lines.\n",
    "        kernel = np.array([[0., 1., 0.], [1., 1., 1.], [0., 1., 0.]],np.uint8)\n",
    "        proc = cv2.dilate(proc, kernel)\n",
    "\n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8acbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corners_of_largest_polygon(img):\n",
    "    opencv_version = cv2.__version__.split('.')[0]\n",
    "    if opencv_version == '3':\n",
    "        _, contours, h = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Find contours\n",
    "    else:\n",
    "        contours, h = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Find contours\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)  # Sort by area, descending\n",
    "    polygon = contours[0]  # Largest image\n",
    "\n",
    "    # Use of `operator.itemgetter` with `max` and `min` allows us to get the index of the point\n",
    "    # Each point is an array of 1 coordinate, hence the [0] getter, then [0] or [1] used to get x and y respectively.\n",
    "\n",
    "    # Bottom-right point has the largest (x + y) value\n",
    "    # Top-left has point smallest (x + y) value\n",
    "    # Bottom-left point has smallest (x - y) value\n",
    "    # Top-right point has largest (x - y) value\n",
    "    bottom_right, _ = max(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "    top_left, _ = min(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "    bottom_left, _ = min(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "    top_right, _ = max(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "\n",
    "    # Return an array of all 4 points using the indices\n",
    "    # Each point is in its own array of one coordinate\n",
    "    return [polygon[top_left][0], polygon[top_right][0], polygon[bottom_right][0], polygon[bottom_left][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52091a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between(p1, p2):\n",
    "    a = p2[0] - p1[0]\n",
    "    b = p2[1] - p1[1]\n",
    "    return np.sqrt((a ** 2) + (b ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31ba8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_warp(img, crop_rect):\n",
    "    # Rectangle described by top left, top right, bottom right and bottom left points\n",
    "    top_left, top_right, bottom_right, bottom_left = crop_rect[0], crop_rect[1], crop_rect[2], crop_rect[3]\n",
    "\n",
    "    # Explicitly set the data type to float32 or `getPerspectiveTransform` will throw an error\n",
    "    src = np.array([top_left, top_right, bottom_right, bottom_left], dtype='float32')\n",
    "\n",
    "    # Get the longest side in the rectangle\n",
    "    side = max([\n",
    "        distance_between(bottom_right, top_right),\n",
    "        distance_between(top_left, bottom_left),\n",
    "        distance_between(bottom_right, bottom_left),\n",
    "        distance_between(top_left, top_right)\n",
    "    ])\n",
    "\n",
    "    # Describe a square with side of the calculated length, this is the new perspective we want to warp to\n",
    "    dst = np.array([[0, 0], [side - 1, 0], [side - 1, side - 1], [0, side - 1]], dtype='float32')\n",
    "\n",
    "    # Gets the transformation matrix for skewing the image to fit a square by comparing the 4 before and after points\n",
    "    m = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # Performs the transformation on the original image\n",
    "    return cv2.warpPerspective(img, m, (int(side), int(side)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "103027f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_grid(img):\n",
    "    \"\"\"Infers 81 cell grid from a square image.\"\"\"\n",
    "    squares = []\n",
    "    side = img.shape[:1]\n",
    "    side = side[0] / 9\n",
    "\n",
    "    # Note that we swap j and i here so the rectangles are stored in the list reading left-right instead of top-down.\n",
    "    for j in range(9):\n",
    "        for i in range(9):\n",
    "            p1 = (i * side, j * side)  # Top left corner of a bounding box\n",
    "            p2 = ((i + 1) * side, (j + 1) * side)  # Bottom right corner of bounding box\n",
    "            squares.append((p1, p2))\n",
    "    return squares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94c235a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_from_rect(img, rect):\n",
    "\treturn img[int(rect[0][1]):int(rect[1][1]), int(rect[0][0]):int(rect[1][0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "785ac82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_centre(img, size, margin=0, background=0):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    def centre_pad(length):\n",
    "        \"\"\"Handles centering for a given length that may be odd or even.\"\"\"\n",
    "        if length % 2 == 0:\n",
    "            side1 = int((size - length) / 2)\n",
    "            side2 = side1\n",
    "        else:\n",
    "            side1 = int((size - length) / 2)\n",
    "            side2 = side1 + 1\n",
    "        return side1, side2\n",
    "\n",
    "    def scale(r, x):\n",
    "        return int(r * x)\n",
    "\n",
    "    if h > w:\n",
    "        t_pad = int(margin / 2)\n",
    "        b_pad = t_pad\n",
    "        ratio = (size - margin) / h\n",
    "        w, h = scale(ratio, w), scale(ratio, h)\n",
    "        l_pad, r_pad = centre_pad(w)\n",
    "    else:\n",
    "        l_pad = int(margin / 2)\n",
    "        r_pad = l_pad\n",
    "        ratio = (size - margin) / w\n",
    "        w, h = scale(ratio, w), scale(ratio, h)\n",
    "        t_pad, b_pad = centre_pad(h)\n",
    "\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    img = cv2.copyMakeBorder(img, t_pad, b_pad, l_pad, r_pad, cv2.BORDER_CONSTANT, None, background)\n",
    "    return cv2.resize(img, (size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c13270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_feature(inp_img, scan_tl=None, scan_br=None):\n",
    "\t\"\"\"\n",
    "\tUses the fact the `floodFill` function returns a bounding box of the area it filled to find the biggest\n",
    "\tconnected pixel structure in the image. Fills this structure in white, reducing the rest to black.\n",
    "\t\"\"\"\n",
    "\timg = inp_img.copy()  # Copy the image, leaving the original untouched\n",
    "\theight, width = img.shape[:2]\n",
    "\n",
    "\tmax_area = 0\n",
    "\tseed_point = (None, None)\n",
    "\n",
    "\tif scan_tl is None:\n",
    "\t\tscan_tl = [0, 0]\n",
    "\n",
    "\tif scan_br is None:\n",
    "\t\tscan_br = [width, height]\n",
    "\n",
    "\t# Loop through the image\n",
    "\tfor x in range(scan_tl[0], scan_br[0]):\n",
    "\t\tfor y in range(scan_tl[1], scan_br[1]):\n",
    "\t\t\t# Only operate on light or white squares\n",
    "\t\t\tif img.item(y, x) == 255 and x < width and y < height:  # Note that .item() appears to take input as y, x\n",
    "\t\t\t\tarea = cv2.floodFill(img, None, (x, y), 64)\n",
    "\t\t\t\tif area[0] > max_area:  # Gets the maximum bound area which should be the grid\n",
    "\t\t\t\t\tmax_area = area[0]\n",
    "\t\t\t\t\tseed_point = (x, y)\n",
    "\n",
    "\t# Colour everything grey (compensates for features outside of our middle scanning range\n",
    "\tfor x in range(width):\n",
    "\t\tfor y in range(height):\n",
    "\t\t\tif img.item(y, x) == 255 and x < width and y < height:\n",
    "\t\t\t\tcv2.floodFill(img, None, (x, y), 64)\n",
    "\n",
    "\tmask = np.zeros((height + 2, width + 2), np.uint8)  # Mask that is 2 pixels bigger than the image\n",
    "\n",
    "\t# Highlight the main feature\n",
    "\tif all([p is not None for p in seed_point]):\n",
    "\t\tcv2.floodFill(img, mask, seed_point, 255)\n",
    "\n",
    "\ttop, bottom, left, right = height, 0, width, 0\n",
    "\n",
    "\tfor x in range(width):\n",
    "\t\tfor y in range(height):\n",
    "\t\t\tif img.item(y, x) == 64:  # Hide anything that isn't the main feature\n",
    "\t\t\t\tcv2.floodFill(img, mask, (x, y), 0)\n",
    "\n",
    "\t\t\t# Find the bounding parameters\n",
    "\t\t\tif img.item(y, x) == 255:\n",
    "\t\t\t\ttop = y if y < top else top\n",
    "\t\t\t\tbottom = y if y > bottom else bottom\n",
    "\t\t\t\tleft = x if x < left else left\n",
    "\t\t\t\tright = x if x > right else right\n",
    "\n",
    "\tbbox = [[left, top], [right, bottom]]\n",
    "\treturn img, np.array(bbox, dtype='float32'), seed_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7c1fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_digit(img, rect, size):\n",
    "\t\"\"\"Extracts a digit (if one exists) from a Sudoku square.\"\"\"\n",
    "\n",
    "\tdigit = cut_from_rect(img, rect)  # Get the digit box from the whole square\n",
    "\n",
    "\t# Use fill feature finding to get the largest feature in middle of the box\n",
    "\t# Margin used to define an area in the middle we would expect to find a pixel belonging to the digit\n",
    "\th, w = digit.shape[:2]\n",
    "\tmargin = int(np.mean([h, w]) / 2.5)\n",
    "\t_, bbox, seed = find_largest_feature(digit, [margin, margin], [w - margin, h - margin])\n",
    "\tdigit = cut_from_rect(digit, bbox)\n",
    "\n",
    "\t# Scale and pad the digit so that it fits a square of the digit size we're using for machine learning\n",
    "\tw = bbox[1][0] - bbox[0][0]\n",
    "\th = bbox[1][1] - bbox[0][1]\n",
    "\n",
    "\t# Ignore any small bounding boxes\n",
    "\tif w > 0 and h > 0 and (w * h) > 100 and len(digit) > 0:\n",
    "\t\treturn scale_and_centre(digit, size, 4)\n",
    "\telse:\n",
    "\t\treturn np.zeros((size, size), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_digit_1(img, pts):\n",
    "    startx, starty = pts[0][0], pt[0][1]\n",
    "    endx, endy = pts[1][0], pts[1][1]\n",
    "    cell = img[starty:endy, startx:endx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_digits(img, squares, size):\n",
    "    \"\"\"Extracts digits from their cells and builds an array\"\"\"\n",
    "    digits = []\n",
    "    img = pre_process_image(img.copy(), skip_dilate=True)\n",
    "#    cv2.imshow('img', img)\n",
    "    for square in squares:\n",
    "        digits.append(extract_digit(img, square, size))\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca09d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grid(path):\n",
    "    original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    processed = pre_process_image(original)\n",
    "    \n",
    "#    cv2.namedWindow('processed',cv2.WINDOW_AUTOSIZE)\n",
    "#    processed_img = cv2.resize(processed, (500, 500))          # Resize image\n",
    "#    cv2.imshow('processed', processed_img)\n",
    "    \n",
    "    corners = find_corners_of_largest_polygon(processed)\n",
    "    cropped = crop_and_warp(original, corners)\n",
    "    \n",
    "#    cv2.namedWindow('cropped',cv2.WINDOW_AUTOSIZE)\n",
    "#    cropped_img = cv2.resize(cropped, (500, 500))              # Resize image\n",
    "#    cv2.imshow('cropped', cropped_img)\n",
    "    \n",
    "    squares = infer_grid(cropped)\n",
    "#    print(squares)\n",
    "    digits = get_digits(cropped, squares, 28)\n",
    "#    print(digits)\n",
    "    final_image = show_digits(digits)\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ede5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sudoku(image_path):\n",
    "    final_image = parse_grid(image_path)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df8e7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = extract_sudoku(r\"C:\\Users\\Devayani K\\sudoku-solver\\sudoku-8.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0906e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('color_img1.jpg', arr)\n",
    "cv2.imshow(\"image\", arr)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5500c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be29b861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a47257a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5125c721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72e1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc38a32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406caad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b821c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517ba96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83076d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
